{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83e3bc0",
   "metadata": {},
   "source": [
    "### Importing Required Libraries for ECG Record Scraping and MySQL Integration\n",
    "\n",
    "In any data-driven Python project, importing the right set of libraries is essential to harness the full potential of the language's capabilities. When it comes to extracting Electrocardiogram (ECG) records from PhysioNet and integrating them into a MySQL database, our success largely depends on having the right tools at our disposal.Below are the libraries that will empower us to accomplish this feat seamlessly:\n",
    "\n",
    "os:\n",
    "The os module provides a way to interact with the operating system. We'll leverage its functionalities to navigate directories, list files, and access file paths efficiently. By using os, we can effortlessly manage the files containing our ECG record data.\n",
    "\n",
    "pandas (pd):\n",
    "Pandas is a powerhouse library for data manipulation and analysis. It provides data structures like DataFrames that are well-suited for organizing and handling tabular data. With pandas, we can efficiently process and manage the scraped ECG record information before saving it to the MySQL database.\n",
    "\n",
    "wfdb:\n",
    "The wfdb library (WaveForm DataBase) is specifically designed to work with physiological signal data like ECGs. It enables us to read and process ECG records in various formats, ensuring that we can extract the essential information needed for our project.\n",
    "\n",
    "pymysql:\n",
    "The pymysql library allows us to connect and interact with MySQL databases using Python. With this library, we can establish a connection to our local MySQL server and perform database-related operations.\n",
    "\n",
    "mysql.connector:\n",
    "This library serves as an alternative MySQL connector for Python. Like pymysql, mysql.connector enables us to connect and interact with MySQL databases in a Pythonic way.\n",
    "\n",
    "SQLAlchemy:\n",
    "SQLAlchemy is a powerful SQL toolkit and Object-Relational Mapper (ORM) for Python. It provides a higher-level interface to interact with databases, making it easier to manage connections and execute queries. We'll utilize SQLAlchemy to create an engine for our MySQL database and facilitate data insertion.\n",
    "\n",
    "By importing these libraries, we equip ourselves with a potent arsenal to tackle the intricacies of web scraping, data manipulation, and database integration. With the right tools in hand, we're ready to embark on our journey to unveil the world of ECG record scraping and MySQL database integration. Let's delve into the heart of our Python program, where these libraries will orchestrate the magic that brings ECG data to life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529de270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import wfdb\n",
    "import pymysql\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a7a36",
   "metadata": {},
   "source": [
    "#### Creating an ECG Record DataFrame from Directory Information\n",
    "In the journey of scraping Electrocardiogram (ECG) records from PhysioNet and integrating them into a MySQL database, one of the pivotal functions that form the backbone of our project is create_record_dataframe(). This function serves as a crucial step in the data extraction process, allowing us to organize and structure the essential information about each ECG record.Let's dive into the intricacies of this function and understand its significance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802bbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record_dataframe(folder_path, sampling_freq, database_name):\n",
    "    record_files = [f.replace('.hea', '') for f in os.listdir(folder_path) if f.endswith('.hea')]\n",
    "    data = pd.DataFrame({'RdID': record_files,\n",
    "                         'SampFreq': [sampling_freq] * len(record_files),\n",
    "                         'sourceDB': [database_name] * len(record_files)})\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498d5bc",
   "metadata": {},
   "source": [
    "##### Function Signature:\n",
    "\n",
    "folder_path: The path to the directory containing the ECG record files. The function will look for files with the \".hea\" extension in this directory.\n",
    "sampling_freq: The sampling frequency of the ECG records. This will be the same for all records in the folder.\n",
    "database_name: The name of the source database from which the records are being extracted.\n",
    "Function Logic:\n",
    "\n",
    "##### Scanning for ECG Record Files:\n",
    "The function first scans the specified folder_path using the os.listdir() method. It looks for files that have the \".hea\" extension, indicating that they contain information about ECG records. The list comprehension [f.replace('.hea', '') for f in os.listdir(folder_path) if f.endswith('.hea')] extracts the record IDs by removing the \".hea\" extension from each filename and stores them in the record_files list.\n",
    "\n",
    "##### Creating the DataFrame:\n",
    "Next, a pandas DataFrame, named data, is created to hold the information about each ECG record. The DataFrame has three columns:\n",
    "\n",
    "'RdID': Represents the record ID, which serves as a unique identifier for each ECG record.\n",
    "'SampFreq': Indicates the common sampling frequency shared by all records in the directory. It is set to sampling_freq for all records.\n",
    "'sourceDB': Stores the name of the source database for these ECG records, which is set to database_name for all records.\n",
    "Returning the DataFrame:\n",
    "The function concludes by returning the DataFrame data, which contains the organized information about the ECG records found in the specified directory.\n",
    "\n",
    "##### Function Usage:\n",
    "The create_record_dataframe() function acts as a crucial preparatory step for the subsequent data insertion into the MySQL database. It allows us to efficiently organize the record IDs, sampling frequencies, and source database names, making it easier to manage and insert the data into the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab916687",
   "metadata": {},
   "source": [
    "#### Establishing a MySQL Connection and Creating the Database\n",
    "\n",
    "In the journey to bring ECG record scraping and MySQL database integration to life, the process of establishing a MySQL connection and creating the database serves as a fundamental building block. This crucial step paves the way for seamlessly managing, storing, and retrieving the scraped ECG record information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbf4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MySQL database connection\n",
    "database = mysql.connector.connect(host='localhost', user='root', passwd='------')\n",
    "cursor = database.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df333019",
   "metadata": {},
   "source": [
    "##### Establishing a MySQL Connection:\n",
    "\n",
    "The code starts by creating a MySQL database connection using the mysql.connector.connect() function. We provide the necessary credentials for connecting to the MySQL server:\n",
    "\n",
    "host: The hostname where the MySQL server is running. In this case, it's set to 'localhost', indicating the local machine.\n",
    "user: The username used to connect to the MySQL server. In this example, it's set to 'root'.\n",
    "passwd: The password associated with the specified username. In this case, the password is '------'.\n",
    "Once the connection is established, we create a cursor object using database.cursor(). The cursor allows us to interact with the MySQL server and execute SQL statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a10eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating database 'ecg_record' if it doesn't exist\n",
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS ecg_record\")\n",
    "database.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0568f3",
   "metadata": {},
   "source": [
    "##### Creating the Database (if not exists):\n",
    "\n",
    "After establishing the connection, the code executes a SQL query using the cursor. The query is \"CREATE DATABASE IF NOT EXISTS ecg_record\". This statement creates a new database named 'ecg_record' if it doesn't already exist in the MySQL server.\n",
    "\n",
    "The IF NOT EXISTS clause ensures that the database is created only if it doesn't exist, preventing any potential errors if the database has already been created.\n",
    "\n",
    "Once the query is executed, we close the database connection using database.close() to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db095722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the 'ecg_record' database\n",
    "engine = create_engine(\"mysql+pymysql://root:053133@localhost/ecg_record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ad676",
   "metadata": {},
   "source": [
    "##### Connecting to the Database using SQLAlchemy:\n",
    "\n",
    "The final part of this code snippet leverages SQLAlchemy to create an engine that will handle the connection to the newly created database 'ecg_record'.\n",
    "\n",
    "We use the create_engine() function from SQLAlchemy to create the engine. The connection string used in this function follows the format \"mysql+pymysql://username:password@hostname/database_name\".\n",
    "\n",
    "In our case, the username is 'root', the password is '------', the hostname is 'localhost', and the database name is 'ecg_record'.\n",
    "This engine will serve as our gateway to interact with the MySQL database, allowing us to perform various operations like data insertion and retrieval efficiently.\n",
    "\n",
    "With this powerful setup, we have successfully established a MySQL connection and created the database 'ecg_record'. Our Python program is now ready to proceed with storing the ECG record information in the database, enabling us to explore and analyze the data in a structured and organized manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b02c2f",
   "metadata": {},
   "source": [
    "#### Creating the 'record' Table and Storing ECG Records in the MySQL Database\n",
    "The journey of our Python program has reached an exciting juncture where we proceed to create the 'record' table and save the extracted ECG record information into our MySQL database. This pivotal step ensures that our valuable data is organized and readily accessible for future analysis and exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5a103f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the 'record' table\n",
    "record_table = create_record_dataframe(folder_path=\"D:\\\\ECG DB\\\\MIT BIH Arr DB\",\n",
    "                                       sampling_freq=360,\n",
    "                                       database_name=\"mitdb\")\n",
    "record_table.to_sql('record', con=engine, if_exists='append', index=False)\n",
    "\n",
    "record_table = create_record_dataframe(folder_path=\"D:\\\\ECG DB\\\\long-term-af-database-1.0.0\\\\files\",\n",
    "                                       sampling_freq=128,\n",
    "                                       database_name='ltaf')\n",
    "record_table.to_sql('record', con=engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cda757",
   "metadata": {},
   "source": [
    "##### Creating the 'record' Table:\n",
    "\n",
    "Before we proceed with saving our ECG records, we first need to create a table in the MySQL database to hold the information. The 'record' table serves as a structured container for organizing our scraped ECG record data.\n",
    "\n",
    "The create_record_dataframe() function we explored earlier comes into play here. It prepares the data in the required format for insertion into the table.\n",
    "\n",
    "##### Storing ECG Records in the Database:\n",
    "\n",
    "The first call to create_record_dataframe() sets folder_path to the directory where the MIT-BIH Arrhythmia Database is located. We specify a sampling frequency of 360 and set the database name to 'mitdb'.\n",
    "\n",
    "The DataFrame record_table is created with the extracted information for the MIT-BIH records.\n",
    "\n",
    "The second call to create_record_dataframe() now sets folder_path to the directory containing the Long-Term AF Database. This time, we set a sampling frequency of 128 and set the database name to 'ltaf'.\n",
    "\n",
    "Another DataFrame record_table is created with the extracted information for the Long-Term AF records.\n",
    "\n",
    "The to_sql() method of pandas DataFrame is used to insert the data into the 'record' table. It takes the following parameters:\n",
    "\n",
    "'record': The name of the table where the DataFrame will be inserted.\n",
    "con=engine: The SQLAlchemy engine we created earlier, allowing us to connect to the MySQL database and execute the insertion.\n",
    "if_exists='append': If the table already exists, this parameter ensures that the data is appended to it rather than creating a new table.\n",
    "index=False: We specify this to avoid storing the DataFrame index in the database, as it's not necessary for our purpose.\n",
    "With this code, we have successfully created the 'record' table in the MySQL database and populated it with the information about ECG records from both the MIT-BIH Arrhythmia Database and the Long-Term AF Database. Our data is now securely stored and readily available for further analysis and exploration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
